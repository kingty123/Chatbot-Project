import sys
sys.stdout.reconfigure(encoding='utf-8')        # ì´ëª¨í‹°ì½˜ ì‚¬ìš© ìš©ì´

import streamlit as st
import sounddevice as sd
import numpy as np
import whisper
import tempfile
import os
import openai
import warnings
import pyttsx3
from gtts import gTTS
from scipy.io.wavfile import write
from dotenv import load_dotenv


st.set_page_config(layout="centered", initial_sidebar_state="expanded")

warnings.filterwarnings("ignore")
ai_img = "IMAGE-you-want"
user_img = "ì‚¬ëŒì´ë¯¸ì§€_1.jpg"


# Whisper ëª¨ë¸ ë¡œë“œ
model = whisper.load_model("base", device="cpu")

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.environ['OPENAI_API_KEY']

st.title("ğŸ™ï¸ SelenaAI ")

with st.sidebar.container():

    # ì†ë„ ì¡°ì ˆ ìŠ¬ë¼ì´ë”
    tts_speed = st.slider("ìŒì„± ì†ë„ ì¡°ì ˆ", min_value=100, max_value=600, value=180, step=5)
    
    # ì‚¬ìš©ìê°€ ì„ íƒí•  ìˆ˜ ìˆëŠ” TTS ì—”ì§„ ëª©ë¡
    tts_engine = st.selectbox(
        "ì‚¬ìš©í•  TTS ì—”ì§„ì„ ì„ íƒí•˜ì„¸ìš”", 
        ["ì˜¤í”„ë¼ì¸", "ì˜¨ë¼ì¸"])

    # ì„¤ì • ì €ì¥
    st.session_state.tts_engine = tts_engine
    st.session_state.tts_speed = tts_speed



# ì±„íŒ… ê¸°ë¡ ìœ ì§€
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []


# ìŒì„± ë…¹ìŒ í•¨ìˆ˜
def record_audio(duration=6, samplerate=44100):
    st.write("ğŸ¤ ë…¹ìŒ ì¤‘ ì…ë‹ˆë‹¤. ë§ì”€ì”€í•´ì£¼ì„¸ìš”!")
    audio_data = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype=np.int16)
    sd.wait()
    temp_audio_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    write(temp_audio_file.name, samplerate, audio_data)
    return temp_audio_file.name


# ìŒì„± -> í…ìŠ¤íŠ¸ : STT
def speech_to_text(audio_file):
    audio = whisper.load_audio(audio_file)
    result = model.transcribe(audio)
    return result["text"]


# í…ìŠ¤íŠ¸ -> ìŒì„± : TTS
def speak_pyttsx3(text):
    if not text:
        return  # ë¹ˆ í…ìŠ¤íŠ¸ëŠ” ë³€í™˜í•˜ì§€ ì•ŠìŒ
    
    engine = pyttsx3.init()
    voices = engine.getProperty('voices')

    # í•œêµ­ì–´ ìŒì„± ì„ íƒ
    for voice in voices:
        if "Heami" in voice.name or "korean" in voice.name.lower():
            engine.setProperty('voice', voice.id)
            break

    engine.setProperty('rate', 180)
    engine.say(text)
    engine.runAndWait()

# gTTS ìŒì„± ì¶œë ¥ í•¨ìˆ˜
def speak_gtts(text):
    tts = gTTS(text=text, lang='ko', slow=False)
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
    tts.save(temp_file.name)
    
    # Streamlitì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ
    st.audio(temp_file.name, format="audio/mp3")
    os.remove(temp_file.name)

# ìµœì¢… TTS ì‹¤í–‰ í•¨ìˆ˜
def speak(text):
    if tts_engine == "pyttsx3 (ì˜¤í”„ë¼ì¸)":
        speak_pyttsx3(text)
    else:
        speak_gtts(text)

# GPT ì‘ë‹µ ìƒì„±
def ask_gpt(user_input):
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4-turbo", 
            messages=[{"role": "user", "content": user_input}]
        )
        return response["choices"][0]["message"]["content"]
    except Exception as e:
        return f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


# ìŒì„± ë…¹ìŒ ë²„íŠ¼
if st.button("ğŸ¤ SelenaAI ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  í¸í•˜ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”"):
    audio_file = record_audio()
    st.success("âœ… ë…¹ìŒ ì™„ë£Œ! ìŒì„± ë³€í™˜ ì¤‘ ì…ë‹ˆë‹¤...")
    text_input = speech_to_text(audio_file)
    st.write(f"ğŸ“ {text_input}")

    response = ask_gpt(text_input)
    st.write(f"ğŸ¤– {response}")

    st.session_state.chat_history.append({"role": "user", "content": text_input})
    st.session_state.chat_history.append({"role": "assistant", "content": response})
    
    speak(response)
    os.remove(audio_file)


st.subheader("ğŸ’¬ ëŒ€í™” ê¸°ë¡")
for chat in st.session_state.chat_history:
    # role = "ğŸ—£ï¸ ì‚¬ìš©ì" if chat["role"] == "user" else "ğŸ¤– ì±—ë´‡"
    # st.write(f"**{role}**: {chat['content']}")

    with st.chat_message(chat["role"]):
        if chat["role"] == "user":
            st.image(user_img, width=50)
        else:
            st.image(ai_img, width=50)
        st.write(chat["content"])


# ìŠ¤í¬ë¡¤ ë²„íŠ¼ ì¶”ê°€ (ë²„íŠ¼ì„ ì˜¤ë¥¸ìª½ í•˜ë‹¨ì— ê³ ì •)
scroll_css = """
    <style>
        .scroll-buttons {
            position: fixed;
            bottom: 20px;
            right: 20px;
            display: flex;
            flex-direction: column;
            gap: 10px;
            z-index: 1000;
        }
        .scroll-buttons button {
            width: 50px;
            height: 50px;
            font-size: 20px;
            border-radius: 50%;
            border: none;
            background-color: #ffffff;
            box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.2);
            cursor: pointer;
        }
        .scroll-buttons button:hover {
            background-color: #f0f0f0;
        }
    </style>
"""
st.markdown(scroll_css, unsafe_allow_html=True)


# JavaScriptë¡œ ìŠ¤í¬ë¡¤ ê¸°ëŠ¥ ì¶”ê°€
scroll_js = """
    <script>
        function scrollToTop() {
            window.scrollTo({top: 0, behavior: 'smooth'});
        }
        function scrollToBottom() {
            window.scrollTo({top: document.body.scrollHeight, behavior: 'smooth'});
        }
    </script>
"""
st.markdown(scroll_js, unsafe_allow_html=True)

# HTMLë¡œ ë²„íŠ¼ ì¶”ê°€ (ì˜¤ë¥¸ìª½ í•˜ë‹¨ì— ê³ ì •)
scroll_buttons_html = """
    <div class="scroll-buttons">
        <button onclick="scrollToTop()">â¬†ï¸</button>
        <button onclick="scrollToBottom()">â¬‡ï¸</button>
    </div>
"""
st.markdown(scroll_buttons_html, unsafe_allow_html=True)



if st.button("ğŸ›‘ ì¢…ë£Œ"):
    st.session_state.chat_history = []
    st.success("ëŒ€í™” ê¸°ë¡ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
