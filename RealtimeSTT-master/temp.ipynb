{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whisper ì‚¬ìš©\n",
    "import whisper\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "#import time\n",
    "import threading                    # ë¹„ë™ê±° ì‘ì—…ì´ë‚˜, ë™ì‹œì— ì—¬ëŸ¬ ì‘ì—… ì²˜ë¦¬\n",
    "import os\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "import pyttsx3\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "#from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "load_dotenv()\n",
    "\n",
    "# API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = API_KEY \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "Created a chunk of size 617, which is longer than the specified 600\n",
      "Created a chunk of size 699, which is longer than the specified 600\n",
      "Created a chunk of size 2225, which is longer than the specified 600\n"
     ]
    }
   ],
   "source": [
    "# Langchainì„ í™œìš©í•˜ê¸° ìœ„í•œ ì„¤ì •ê³¼ RAG ì„¤ì •ì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "llm = ChatOpenAI(model='gpt-4',\n",
    "    temperature=0.7)\n",
    "cache_dir = LocalFileStore(\"./.cache/practice/\")\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "#retriever = FAISS.load_local(\"./refer.txt\", OpenAIEmbeddings(), allow_dangerous_deserialization=True)\n",
    "\n",
    "\n",
    "loader = UnstructuredFileLoader(\"refer.txt\")\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 15:29:46.491 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 15:29:46.493 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 15:29:46.495 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 15:29:46.498 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 15:29:46.499 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 15:29:46.500 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 15:29:46.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 15:29:46.504 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 15:29:46.505 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 15:29:46.506 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 15:29:46.506 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 15:29:46.508 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 15:29:46.508 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 15:29:46.514 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 15:29:46.514 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 15:29:46.514 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 15:29:46.514 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 15:29:46.514 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 15:29:46.514 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function Halo.__init__.<locals>.clean_up at 0x000001F22E02CC20> (for post_run_cell), with arguments args (<ExecutionResult object at 1f22e135ad0, execution_count=22 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 1f22c3fff50, raw_cell=\"#from streamlit_geolocation import streamlit_geolo..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/INO04/Downloads/RealtimeSTT-master/temp.ipynb#X11sZmlsZQ%3D%3D> result=None>,),kwargs {}:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function Halo.__init__.<locals>.clean_up at 0x000001F22E02DB20> (for post_run_cell), with arguments args (<ExecutionResult object at 1f22e135ad0, execution_count=22 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 1f22c3fff50, raw_cell=\"#from streamlit_geolocation import streamlit_geolo..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/INO04/Downloads/RealtimeSTT-master/temp.ipynb#X11sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function Halo.__init__.<locals>.clean_up at 0x000001F22E02CF40> (for post_run_cell), with arguments args (<ExecutionResult object at 1f22e135ad0, execution_count=22 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 1f22c3fff50, raw_cell=\"#from streamlit_geolocation import streamlit_geolo..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/INO04/Downloads/RealtimeSTT-master/temp.ipynb#X11sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function Halo.__init__.<locals>.clean_up at 0x000001F22DE48680> (for post_run_cell), with arguments args (<ExecutionResult object at 1f22e135ad0, execution_count=22 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 1f22c3fff50, raw_cell=\"#from streamlit_geolocation import streamlit_geolo..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/INO04/Downloads/RealtimeSTT-master/temp.ipynb#X11sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function Halo.__init__.<locals>.clean_up at 0x000001F22E02D620> (for post_run_cell), with arguments args (<ExecutionResult object at 1f22e135ad0, execution_count=22 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 1f22c3fff50, raw_cell=\"#from streamlit_geolocation import streamlit_geolo..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/INO04/Downloads/RealtimeSTT-master/temp.ipynb#X11sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function Halo.__init__.<locals>.clean_up at 0x000001F22DD63740> (for post_run_cell), with arguments args (<ExecutionResult object at 1f22e135ad0, execution_count=22 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 1f22c3fff50, raw_cell=\"#from streamlit_geolocation import streamlit_geolo..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/INO04/Downloads/RealtimeSTT-master/temp.ipynb#X11sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function Halo.__init__.<locals>.clean_up at 0x000001F22E02E980> (for post_run_cell), with arguments args (<ExecutionResult object at 1f22e135ad0, execution_count=22 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 1f22c3fff50, raw_cell=\"#from streamlit_geolocation import streamlit_geolo..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/INO04/Downloads/RealtimeSTT-master/temp.ipynb#X11sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function Halo.__init__.<locals>.clean_up at 0x000001F18409C680> (for post_run_cell), with arguments args (<ExecutionResult object at 1f22e135ad0, execution_count=22 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 1f22c3fff50, raw_cell=\"#from streamlit_geolocation import streamlit_geolo..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/INO04/Downloads/RealtimeSTT-master/temp.ipynb#X11sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function Halo.__init__.<locals>.clean_up at 0x000001F22E02E700> (for post_run_cell), with arguments args (<ExecutionResult object at 1f22e135ad0, execution_count=22 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 1f22c3fff50, raw_cell=\"#from streamlit_geolocation import streamlit_geolo..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/INO04/Downloads/RealtimeSTT-master/temp.ipynb#X11sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "#from streamlit_geolocation import streamlit_geolocation\n",
    "\n",
    "\n",
    "# Streamlit ì„¸ì…˜ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. ì´ëŠ” ëŒ€í™” ë‚´ì—­ì„ ì €ì¥í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "if 'chat_history' not in st.session_state:\n",
    "    st.session_state.chat_history = []\n",
    "if 'question' not in st.session_state:\n",
    "    st.session_state.question = \"\"\n",
    "if 'mode' not in st.session_state:\n",
    "    st.session_state.mode = \"voice\" # ê¸°ë³¸ ëª¨ë“œ = ìŒì„±\n",
    "\n",
    "# ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •\n",
    "ai_avatar = \"karina_1-removebg-preview.png\"  # AI ì•„ë°”íƒ€ ì´ë¯¸ì§€\n",
    "user_avatar = \"ì‚¬ëŒì´ë¯¸ì§€_1.jpg\"  # ì‚¬ìš©ì ì•„ë°”íƒ€ ì´ë¯¸ì§€\n",
    "\n",
    "# ì´ë¯¸ì§€ Base64 ë³€í™˜ í•¨ìˆ˜\n",
    "def get_image_base64(image_path):\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        return base64.b64encode(img_file.read()).decode()\n",
    "\n",
    "\n",
    "\n",
    "# ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "def ask_gpt(user_question):\n",
    "    # ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ê¸°ë°˜ìœ¼ë¡œ CHATGPTì—ê²Œ ìš”ì²­í•  ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            ë‹¹ì‹ ì€ 'Selena'ë¼ëŠ” ì°¨ëŸ‰ìš© ì¸ê³µì§€ëŠ¥ ë¹„ì„œì…ë‹ˆë‹¤. ì¹œê·¼í•˜ê³  ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê²Œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ë©°, ìš´ì „ ì¤‘ì—ë„ ì•ˆì „í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì´ ì£¼ëœ ì—­í• ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ í•˜ë©´ ì •í™•í•˜ê³  ëª…í™•í•œ ë‹µë³€ì„ ì£¼ë˜, ìš´ì „ ì¤‘ì—ë„ í¸ì•ˆí•˜ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ê°„ê²°í•˜ê³  ì¹œê·¼í•˜ê²Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ì•„ë˜ ì§€ì¹¨ì„ ë”°ë¼ì£¼ì„¸ìš”:\n",
    "\n",
    "            1. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì‹ ì¤‘í•˜ê²Œ ë¶„ì„í•©ë‹ˆë‹¤.\n",
    "            2. ëª…í™•í•˜ê³  ê°„ê²°í•˜ë©°, ìš´ì „ ì¤‘ì—ë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë‹µë³€í•©ë‹ˆë‹¤.\n",
    "            3. ì§ˆë¬¸ì´ ë³µì¡í•˜ë©´ ì´í•´í•˜ê¸° ì‰¬ìš´ ì‘ì€ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì„¤ëª…í•©ë‹ˆë‹¤.\n",
    "            4. ì˜ˆì‹œë‚˜ ë¹„ìœ ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°œë…ì„ ì‰½ê²Œ í’€ì–´ ì„¤ëª…í•©ë‹ˆë‹¤.\n",
    "            5. ë‹µë³€ì„ ì˜ ëª¨ë¥´ê² ë‹¤ë©´ ê·¸ ì‚¬ì‹¤ì„ ì¸ì •í•˜ê³ , ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.\n",
    "            6. ì‚¬ìš©ìê°€ ë” ì•Œì•„ë³¼ ìˆ˜ ìˆë„ë¡ í›„ì† ì§ˆë¬¸ì„ ìœ ë„í•˜ê±°ë‚˜ ê´€ë ¨ëœ ì£¼ì œë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.\n",
    "            7. í•­ìƒ ê¸ì •ì ì´ê³  ê²©ë ¤í•˜ëŠ” íƒœë„ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "            8. ìš´ì „ ì¤‘ì—ëŠ” ì•ˆì „ì„ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ëŒ€í™”ë¥¼ ìœ ë„í•©ë‹ˆë‹¤.\n",
    "            \\n\\n\n",
    "            {context}\",\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    chain = (\n",
    "        {\n",
    "            \"context\": retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "    )\n",
    "    result = chain.invoke(user_question)\n",
    "        \n",
    "    return result.content\n",
    "\n",
    "\n",
    "\n",
    "# ì§ˆë¬¸ ì…ë ¥ í´ë¦¬ì–´ í•¨ìˆ˜\n",
    "def clear_input():\n",
    "    st.session_state.question = \"\"\n",
    "\n",
    "\n",
    "# ìŒì„±ì„ í•©ì„±í•˜ëŠ” í•¨ìˆ˜ : TTS\n",
    "def speak(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "from RealtimeSTT import AudioToTextRecorder\n",
    "import pyautogui\n",
    "\n",
    "\n",
    "# # ìŒì„± ì¸ì‹ ì½œë°± í•¨ìˆ˜\n",
    "# def recognize_audio(indata, frames, time, status):\n",
    "#     if status:\n",
    "#         print(status)\n",
    "\n",
    "#     # numpy ë°°ì—´ì„ ë°”ì´íŠ¸ë¡œ ë³€í™˜\n",
    "#     audio = np.frombuffer(indata, dtype=np.float32)\n",
    "\n",
    "#     # ì´ë¦„ í˜¸ëª…í•˜ë©´ STT ì‹œì‘\n",
    "#     if detect_keyword(audio):\n",
    "#         print(\"ì•ˆë…•í•˜ì„¸ìš”. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?ğŸ˜Š\")\n",
    "#         # ë³„ë„ì˜ ìŠ¤ë ˆë“œì—ì„œ ëª…ë ¹ì„ ë“£ê³  ì²˜ë¦¬\n",
    "#         threading.Thread(target=process_command).start()\n",
    "#         # ë™ê¸°ì²˜ë¦¬\n",
    "#         # process_command()\n",
    "\n",
    "\n",
    "# í‚¤ì›Œë“œ ê°ì§€ í•¨ìˆ˜(ê¸°ë³¸ ì˜ˆì‹œ)\n",
    "def detect_keyword(audio):\n",
    "    #return np.random.rand() > 0.97  # 3% í™•ë¥ ë¡œ í‚¤ì›Œë“œ ê°ì§€\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    mel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)\n",
    "    result = model.transcribe(mel)\n",
    "\n",
    "    # ê°ì§€ëœ í…ìŠ¤íŠ¸ì—ì„œ \"Hey\"ë¥¼ ì°¾ìŒ\n",
    "    if \"Selena\" in result['text'].lower():\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# # ì‚¬ìš©ìì˜ ëª…ë ¹ì„ ë“£ëŠ” í•¨ìˆ˜\n",
    "# def listen_for_command():\n",
    "#     print(\"ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš” ğŸ˜Š\")\n",
    "#     time.sleep(10)  # ì‚¬ìš©ìì—ê²Œ ë§ì„ í•  ì‹œê°„ì„ ì¤Œ\n",
    "#     recording = sd.rec(int(5 * 44100), samplerate=44100, channels=1, dtype='float32')\n",
    "#     sd.wait()  # ë…¹ìŒ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°\n",
    "#     return recording\n",
    "\n",
    "\n",
    "# # ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜\n",
    "# def transcribe_audio(audio):\n",
    "#     audio = whisper.pad_or_trim(audio)\n",
    "#     mel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)\n",
    "#     result = model.transcribe(mel)\n",
    "#     return result['text']\n",
    "\n",
    "\n",
    "# # process_command() : íŠ¹ì • í‚¤ì›Œë“œë¥¼ ê°ì§€í–ˆì„ ë•Œ í˜¸ì¶œë˜ë©°, ì‚¬ìš©ìì˜ ìŒì„± ëª…ë ¹ ì²˜ë¦¬\n",
    "# def process_command():\n",
    "#     audio = listen_for_command()            # ì‚¬ìš©ìê°€ ìŒì„±ìœ¼ë¡œ ëª…ë ¹ì„ ì…ë ¥í•  ìˆ˜ ìˆë„ë¡ ëŒ€ê¸°ê¸°\n",
    "#     command = transcribe_audio(audio)       # ìŒì„± -> í…ìŠ¤íŠ¸\n",
    "#     print(\"ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ : {command}\")        # ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ì¶œë ¥\n",
    "#     # print(f\"ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­: {command}\")\n",
    "#     response = respond_to_command(command)             # ìœ ì € ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ ì ì ˆí•œ ì‘ë‹µ ì œê³µ\n",
    "#     print(response)\n",
    "#     pyautogui.typewrite(command)            # í…ìŠ¤íŠ¸(ì‚¬ìš©ì ëª…ë ¹)ë¥¼ ì±„íŒ…ì°½ì— ì…ë ¥\n",
    "\n",
    "\n",
    "# process_command() : íŠ¹ì • í‚¤ì›Œë“œë¥¼ ê°ì§€í–ˆì„ ë•Œ í˜¸ì¶œë˜ë©°, ì‚¬ìš©ìì˜ ìŒì„± ëª…ë ¹ ì²˜ë¦¬\n",
    "def process_command(text):\n",
    "    print(f\"ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­: {text}\")\n",
    "    response = respond_to_command(text)\n",
    "    print(response)\n",
    "    pyautogui.typewrite(response)           # ì‘ë‹µì„ ì±„íŒ…ì°½ì— ì…ë ¥\n",
    "\n",
    "\n",
    "# ìˆ˜ì • í•„ìš” : ëª…ë ¹ì— ëŒ€í•œ ì‘ë‹µì„ ì œê³µí•˜ëŠ” í•¨ìˆ˜\n",
    "def respond_to_command(command):\n",
    "    # ì˜ˆì‹œ: íŠ¹ì • ëª…ë ¹ì–´ì— ëŒ€í•œ ì‘ë‹µ ì²˜ë¦¬\n",
    "    if \"ë‚ ì”¨\" in command:\n",
    "        response = \"ì˜¤ëŠ˜ì˜ ë‚ ì”¨ëŠ” ë§‘ìŠµë‹ˆë‹¤.â˜€ï¸\"\n",
    "    elif \"ì‹œê°„\" in command:\n",
    "        response = \"í˜„ì¬ ì‹œê°„ì€ 3ì‹œì…ë‹ˆë‹¤.ğŸ•’\"\n",
    "    else:\n",
    "        response = \"ìš”ì²­í•˜ì‹  ë‚´ìš©ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ì£¼ì„¸ìš” ğŸ¥²\"\n",
    "    return response\n",
    "\n",
    "\n",
    "def listen_for_audio():\n",
    "    recorder = AudioToTextRecorder()\n",
    "    while True:\n",
    "        recorder.text(process_command)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # streamlit page configuration\n",
    "    st.set_page_config(layout=\"wide\", page_title=\"Wellcome, I'm Selena\")\n",
    "    # í˜ì´ì§€ ì œëª©\n",
    "    st.title('Selena')\n",
    "\n",
    "    # CSS ìŠ¤íƒ€ì¼ ì •ì˜\n",
    "    st.markdown(\"\"\"\n",
    "    <style>\n",
    "    .chat-container {\n",
    "        display: flex;\n",
    "        align-items: start;\n",
    "        margin-bottom: 20px;\n",
    "        width: 100%;\n",
    "    }\n",
    "\n",
    "    .chat-image {\n",
    "        width: 100px;\n",
    "        height: 150px;\n",
    "        border-radius: 10%;\n",
    "        margin: 0 15px;\n",
    "        object-fit : cover;\n",
    "    }\n",
    "    .chat-image.ai {\n",
    "        flex-direction: row-reverse;\n",
    "        align: right;\n",
    "        align-items: flex-start;\n",
    "        justify-content: flex-end;\n",
    "    }\n",
    "    .chat-message {\n",
    "        background-color: #f0f2f6;\n",
    "        padding: 10px;\n",
    "        border-radius: 10px;\n",
    "        max-width: 80%;\n",
    "    }\n",
    "\n",
    "    .chat-container.ai {\n",
    "        flex-direction: row-reverse;\n",
    "        text-align: auto;\n",
    "    }         \n",
    "                \n",
    "    .chat-message.ai {\n",
    "        margin-right: 0;\n",
    "        text-align: auto;\n",
    "    }   \n",
    "\n",
    "    </style>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "    # ìŒì„± ë° ì±„íŒ…ëª¨ë“œ ì„ íƒ\n",
    "    # mode = st.radio(\"Please choose 1 of them : \", [\"voice\", \"chat\"])\n",
    "    # st.session_state.mode = mode\n",
    "    question = st.text_input(\"ì–¸ì œë“  í¸í•˜ê²Œ ë¬¼ì–´ë³´ì„¸ìš”\", value=st.session_state.question, key=\"user_input\")\n",
    "\n",
    "\n",
    "    # ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë²„íŠ¼\n",
    "    if question and (st.button('ë‹µë³€') or question != st.session_state.get('previous_question', '')):\n",
    "        st.session_state['previous_question'] = question\n",
    "        answer = ask_gpt(question)  # GPT-3 ëª¨ë¸ì„ í˜¸ì¶œí•˜ì—¬ ë‹µë³€ì„ ë°›ìŠµë‹ˆë‹¤.\n",
    "\n",
    "        st.session_state.chat_history.append(f\"Question: {question}\")\n",
    "        st.session_state.chat_history.append(f\"Answer: {answer}\")\n",
    "        st.session_state.question = \"\"  # ì…ë ¥ í•„ë“œ í´ë¦¬ì–´\n",
    "\n",
    "        # # ìŒì„± ëª¨ë“œì¼ ê²½ìš° ìŒì„±ìœ¼ë¡œ ë‹µë³€ ì½ê¸°\n",
    "        # if st.session_state.mode == \"voice\":\n",
    "        #     speak(answer)\n",
    "\n",
    "            \n",
    "        # ëŒ€í™” ë‚´ì—­ í‘œì‹œ\n",
    "        for message in st.session_state.chat_history:\n",
    "            if message.startswith(\"Question:\"):\n",
    "            # ì‚¬ìš©ìì™€ ai ë©”ì„¸ì§€ êµ¬ë¶„\n",
    "            #user_message = st.session_state.chat_history[i]\n",
    "            #ai_message = st.session_state.chat_history[i + 1]\n",
    "            \n",
    "                # ì‚¬ìš©ì ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ\n",
    "                st.markdown(\n",
    "                    f\"\"\"\n",
    "                    <div class=\"chat-container\">\n",
    "                        <img src=\"data:image/jpeg;base64,{get_image_base64(user_avatar)}\" class=\"chat-image\">\n",
    "                        <div class=\"chat-message\">{message}</div>\n",
    "                        <div class=\"button-group\">\n",
    "                            <button class=\"copy-btn\" onclick=\"copyToClipboard('{message}')\"> âœ”ï¸ </button>\n",
    "                            <button class=\"eval-btn\" onclick=\"evaluateResponse('Good')\"> ğŸ‘ </button>\n",
    "                            <button class=\"eval-btn\" onclick=\"evaluateResponse('Bad')\"> ğŸ‘ </button>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                    \"\"\",\n",
    "                    unsafe_allow_html=True\n",
    "                )\n",
    "\n",
    "            else : \n",
    "                # ai ë‹µë³€ ì»¨í…Œì´ë„ˆ\n",
    "                st.markdown(\n",
    "                    f\"\"\"\n",
    "                    <div class=\"chat-container ai\">\n",
    "                        <img src=\"data:image/jpeg;base64,{get_image_base64(ai_avatar)}\" class=\"chat-image\">\n",
    "                        <div class=\"chat-message ai\">{message}</div>\n",
    "                        <div class=\"button-group\">\n",
    "                            <button class=\"copy-btn\" onclick=\"copyToClipboard('{message}')\"> âœ”ï¸ </button>\n",
    "                            <button class=\"eval-btn\" onclick=\"evaluateResponse('Good')\"> ğŸ‘ </button>\n",
    "                            <button class=\"eval-btn\" onclick=\"evaluateResponse('Bad')\"> ğŸ‘ </button>    \n",
    "                        </div>\n",
    "                    </div>\n",
    "                    \"\"\", \n",
    "                    unsafe_allow_html=True\n",
    "                )\n",
    "\n",
    "        # ìë™ ìŠ¤í¬ë¡¤ ì•„ë˜ë¡œ\n",
    "        st.markdown(\"<script>window.scrollTo(0, document.body.scrollHeight);</script>\", unsafe_allow_html=True)\n",
    "        # ìë™ ìŠ¤í¬ë¡¤ ìœ„ë¡œ (ì˜ˆ: 100px ìœ„ë¡œ ì´ë™)\n",
    "        st.markdown(\"<script>window.scrollBy(0, -100);</script>\", unsafe_allow_html=True)\n",
    "\n",
    "            \n",
    "    else:\n",
    "        st.error(\"Please enter a question.\")\n",
    "\n",
    "\n",
    "\n",
    "    # ìë°”ìŠ¤í¬ë¦½íŠ¸ í•¨ìˆ˜ ì¶”ê°€ (ë³µì‚¬ ë° í‰ê°€ ê¸°ëŠ¥)\n",
    "    st.markdown(\"\"\"\n",
    "    <div id=\"scroll-top\" onclick=\"window.scrollTo(0,0)\">â¬†ï¸</div>\n",
    "    <div id=\"scroll-bottom\" onclick=\"window.scrollTo(0,document.body.scrollHeight)\">â¬‡ï¸</div>\n",
    "    <script>\n",
    "        function copyToClipboard(text) {\n",
    "            navigator.clipboard.writeText(text).then(() => {\n",
    "                alert('Copied to clipboard');\n",
    "            });\n",
    "        }\n",
    "\n",
    "        function evaluateResponse(evaluation) {\n",
    "            alert('You rated this response as: ' + evaluation);\n",
    "        }\n",
    "    </script>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "\n",
    "#    .        .       .   .     \n",
    "\n",
    "        # recorder = AudioToTextRecorder()\n",
    "        # while True:\n",
    "        #      recorder.text(process_command)         # ì‚¬ìš©ìê°€ ìŒì„±ì„ ì…ë ¥í•  ë•Œ ë§ˆë‹¤, í•´ë‹¹ ì½”ë“œê°€ í˜¸ì¶œë˜ì–´ process_command ì‹¤í–‰\n",
    "    \n",
    "    # # ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘\n",
    "    # with sd.RawInputStream(callback=recognize_audio, channels=1, samplerate=44100, dtype='float32'):\n",
    "    #     print(\"Listening...\")\n",
    "    #     sd.sleep(-1)  # ë¬´í•œ ëŒ€ê¸°\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Velog ì¶”ì²œ ë°©ë²•\n",
    "from fastapi import FastAPI, File, UploadFile, HTTPException, Body\n",
    "from fastapi.responses import JSONResponse\n",
    "import whisper\n",
    "from openai import OpenAI\n",
    "import os"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
