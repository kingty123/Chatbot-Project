{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whisper 사용하여 STT 실행\n",
    "import os\n",
    "import whisper\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import time\n",
    "#import threading                    # 비동거 작업이나, 동시에 여러 작업 처리\n",
    "import os\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "import pyttsx3\n",
    "\n",
    "# GPT-4로 TTS 실행\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whisper 모델 로드\n",
    "model = whisper.load_model(\"base\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경변수 로드\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain 설정\n",
    "# Langchain setup\n",
    "llm = ChatOpenAI(model='gpt-4', temperature=0.7)\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",  # separator로 올바르게 설정\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whisper를 통한 stt\n",
    "def audio_stt():\n",
    "    samplerate = 16000\n",
    "    duration = 3            # 초기설정 3초\n",
    "\n",
    "    audio = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16')\n",
    "    sd.wait()\n",
    "\n",
    "    # whisper를 사용하여 stt\n",
    "    audio_input = whisper.pad_or_trim(audio)\n",
    "    mel = whisper.log_mel_spectrogram(audio_input, n_mel=model.dims.n_mels).to(model.device)\n",
    "    result = model.transcribe(mel)\n",
    "    return result['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음성 감지 시감 설정\n",
    "def listen_until_silence(silence_threshold=0.02, max_duration=10):\n",
    "    \"\"\"\n",
    "    사용자의 음성을 듣고, 말하는 중이 아니면 녹음을 종료한다.\n",
    "    silence_threshold : 음성이 감지되지 않는 경우로 판단하는 임계값\n",
    "    amx_duration : 최대 녹음 시간(s)\n",
    "    \"\"\"\n",
    "\n",
    "    samplerate = 16000\n",
    "    silence_duration = 0\n",
    "    audio_data = []\n",
    "\n",
    "    with sd.InputStream(callback=lambda indata, frames, time, status: audio_data.append(indata), channels=1, samplerate=samplerate, dtype='int16'):\n",
    "        print(\"잠시만 기다려 주세요..\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        while True:\n",
    "            if time.time() - start_time > max_duration:\n",
    "                break   # 최대 녹음 시간 초과 시 종료\n",
    "\n",
    "            # 실시간 오디오 신호의 평균 에너지\n",
    "            energy = np.linalg.norm(audio_data[-1])**2\n",
    "            if energy < silence_threshold:\n",
    "                silence_duration += 1\n",
    "                if silence_duration > 2:        # 2초 이상 소리가 없으면 멈춤\n",
    "                    print(\"응답 생성 중입니다. 잠시만 기다려 주세요..\")\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    silence_duration = 0        # 음성 감지되면 리셋\n",
    "\n",
    "    \n",
    "    # 받은 음성 데이터를 whisper로 변환\n",
    "    audio = np.concatenate(audio_data, axis=0)\n",
    "    audio_input = whisper.pad_or_trim(audio)\n",
    "    mel = whisper.log_mel_spectrogram(audio_input, n_mels=model.dims.n_mels).to(model.device)\n",
    "    result = model.transcribe(mel)\n",
    "\n",
    "    return result['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt-4를 사용하여 질문에 대한 답변 생성\n",
    "def ask_gpt(user_question):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [(\n",
    "            \"system\", \"당신은 차량용 챗봇 Selena 입니다.\"), (\"user\", user_question)\n",
    "        ])\n",
    "\n",
    "    result = llm.invoke({\"question\": user_question, \"context\": retriever})\n",
    "    return result.content    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts\n",
    "def speak(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selena 인식 함수\n",
    "def detect_keyword(audio):\n",
    "    audio_input = whisper.pad_or_trim(audio)\n",
    "    mel = whisper.log_mel_spectrigram(audio_input, n_mels=model.dims.n_mels).to(model.device)\n",
    "    result = model.transcribe(mel)\n",
    "\n",
    "    if \"Selena\" in result['text'].lower():\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음성 처리 및 명령 처리 함수\n",
    "def process_audio_command():\n",
    "    # 사용자 음성 인식 후 질문 받기\n",
    "    print(\"\")\n",
    "    audio = listen_until_silence()\n",
    "\n",
    "    # 음성이 selena를 포함하는 지확인\n",
    "    if detect_keyword(audio):\n",
    "        print(\"안녕하세요\")\n",
    "\n",
    "        # 사용자가 질문할 때 까지 대기\n",
    "        question = listen_until_silence()\n",
    "        print(f\"질문 : {question}\")\n",
    "\n",
    "        # gpt-4로 답변 생성\n",
    "        answer = ask_gpt(question)\n",
    "        print(f\"답변 : {answer}\")\n",
    "\n",
    "        # 음성으로 답변 전달\n",
    "        speak(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 16:19:34.381 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-17 16:19:34.384 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-17 16:19:34.468 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-02-17 16:19:34.468 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# streamlit UI\n",
    "st.set_page_config(layout=\"wide\", page_title=\"AI Assistant\")\n",
    "st.title(\"AI Assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 16:20:13.439 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-17 16:20:13.440 Session state does not function when running a script without `streamlit run`\n",
      "2025-02-17 16:20:13.441 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-17 16:20:13.441 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-17 16:20:13.442 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-17 16:20:13.444 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-17 16:20:13.446 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-17 16:20:13.446 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "PortAudioError",
     "evalue": "Error querying device -1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPortAudioError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m     speak(answer)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m#음성처리 및 질문-답변 과정을 동기적으로 실행\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     \u001b[43mprocess_audio_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m, in \u001b[0;36mprocess_audio_command\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess_audio_command\u001b[39m():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# 사용자 음성 인식 후 질문 받기\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mlisten_until_silence\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# 음성이 selena를 포함하는 지확인\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m detect_keyword(audio):\n",
      "Cell \u001b[1;32mIn[16], line 13\u001b[0m, in \u001b[0;36mlisten_until_silence\u001b[1;34m(silence_threshold, max_duration)\u001b[0m\n\u001b[0;32m     10\u001b[0m silence_duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m audio_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInputStream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplerate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamplerate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mint16\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m잠시만 기다려 주세요..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\sounddevice.py:1440\u001b[0m, in \u001b[0;36mInputStream.__init__\u001b[1;34m(self, samplerate, blocksize, device, channels, dtype, latency, extra_settings, callback, finished_callback, clip_off, dither_off, never_drop_input, prime_output_buffers_using_stream_callback)\u001b[0m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, samplerate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, blocksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1409\u001b[0m              device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, latency\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1410\u001b[0m              extra_settings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, finished_callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1411\u001b[0m              clip_off\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither_off\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, never_drop_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1412\u001b[0m              prime_output_buffers_using_stream_callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"PortAudio input stream (using NumPy).\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m \n\u001b[0;32m   1415\u001b[0m \u001b[38;5;124;03m    This has the same methods and attributes as `Stream`, except\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1438\u001b[0m \n\u001b[0;32m   1439\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1440\u001b[0m     \u001b[43m_StreamBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrap_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marray\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_remove_self\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\sounddevice.py:828\u001b[0m, in \u001b[0;36m_StreamBase.__init__\u001b[1;34m(self, kind, samplerate, blocksize, device, channels, dtype, latency, extra_settings, callback, finished_callback, clip_off, dither_off, never_drop_input, prime_output_buffers_using_stream_callback, userdata, wrap_callback)\u001b[0m\n\u001b[0;32m    825\u001b[0m         samplerate \u001b[38;5;241m=\u001b[39m isamplerate\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_samplesize, samplerate \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m--> 828\u001b[0m         \u001b[43m_get_stream_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mextra_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplerate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    830\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device \u001b[38;5;241m=\u001b[39m parameters\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channels \u001b[38;5;241m=\u001b[39m parameters\u001b[38;5;241m.\u001b[39mchannelCount\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\sounddevice.py:2708\u001b[0m, in \u001b[0;36m_get_stream_parameters\u001b[1;34m(kind, device, channels, dtype, latency, extra_settings, samplerate)\u001b[0m\n\u001b[0;32m   2705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m samplerate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2706\u001b[0m     samplerate \u001b[38;5;241m=\u001b[39m default\u001b[38;5;241m.\u001b[39msamplerate\n\u001b[1;32m-> 2708\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[43mquery_devices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m channels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2710\u001b[0m     channels \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m kind \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_channels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\sounddevice.py:572\u001b[0m, in \u001b[0;36mquery_devices\u001b[1;34m(device, kind)\u001b[0m\n\u001b[0;32m    570\u001b[0m info \u001b[38;5;241m=\u001b[39m _lib\u001b[38;5;241m.\u001b[39mPa_GetDeviceInfo(device)\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m info:\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PortAudioError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError querying device \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m info\u001b[38;5;241m.\u001b[39mstructVersion \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    574\u001b[0m name_bytes \u001b[38;5;241m=\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mstring(info\u001b[38;5;241m.\u001b[39mname)\n",
      "\u001b[1;31mPortAudioError\u001b[0m: Error querying device -1"
     ]
    }
   ],
   "source": [
    "# 질문 입력 및 답변\n",
    "question = st.text_input(\"편하게 질문하세요\", value=st.session_state.get(\"question\", \"\"))\n",
    "\n",
    "if question and st.button('Submit'):\n",
    "    st.session_state[\"question\"] = question\n",
    "    answer = ask_gpt(question)\n",
    "    st.write(answer)\n",
    "    speak(answer)\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    #음성처리 및 질문-답변 과정을 동기적으로 실행\n",
    "    process_audio_command()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RealtimeSTT import AudioTextRecorder               # AudioTextRecorder : 실시간 STT 처리\n",
    "import pyautogui\n",
    "\n",
    "# 키워드 감지 함수\n",
    "def detect_keyword(audio):\n",
    "    # 사용자 음성 STT\n",
    "    audio = whisper.pad_or_trim(audio)          # audio 데이터 padding or trim\n",
    "    mel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)         # audio 데이터를 멜 스펙트로그램으로 변환\n",
    "    result = model.transcribe(mel)      # mel_spectrogram을 텍스트로 변환\n",
    "    #user_input = result['text']\n",
    "\n",
    "    # 감지된 result에서 Selena 찾기\n",
    "    if \"Selena\" in result['text'].lower():\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# process_command : 특정 키워드를 감지했을 때 호출되며, 사용자의 음성 명령 처리\n",
    "def process_command(text):\n",
    "    print(f\"질문: {text}\")\n",
    "    response = respond_to_command(text)\n",
    "    print(response)\n",
    "    pyautogui.typewrite(response)\n",
    "\n",
    "# respond_to_command : 질문에 대한 응답 제공\n",
    "def respond_to_command(command):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\langchain_community\\chat_models\\anthropic.py:23: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_community.llms.anthropic import _AnthropicCommon\n",
      "c:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "ename": "PydanticUserError",
     "evalue": "The `__modify_schema__` method is not supported in Pydantic v2. Use `__get_pydantic_json_schema__` instead in class `SecretStr`.\n\nFor further information visit https://errors.pydantic.dev/2.10/u/custom-json-schema",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPydanticUserError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstreamlit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mst\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#from langchain_openai import ChatOpenAI\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAISS\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\langchain\\chat_models\\__init__.py:27\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m chat_models\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# If not in interactive env, raise warning.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive_env():\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\langchain_community\\chat_models\\__init__.py:20\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"**Chat Models** are a variation on language models.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mWhile Chat Models use language models under the hood, the interface they expose\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    AIMessage, BaseMessage, HumanMessage\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manthropic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatAnthropic\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manyscale\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatAnyscale\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mazure_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\langchain_community\\chat_models\\anthropic.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGeneration, ChatGenerationChunk, ChatResult\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt_values\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PromptValue\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manthropic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _AnthropicCommon\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_convert_one_message_to_text\u001b[39m(\n\u001b[0;32m     27\u001b[0m     message: BaseMessage,\n\u001b[0;32m     28\u001b[0m     human_prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m     29\u001b[0m     ai_prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m     30\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     31\u001b[0m     content \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, message\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\langchain_community\\llms\\anthropic.py:145\u001b[0m\n\u001b[0;32m    140\u001b[0m         stop\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mHUMAN_PROMPT])\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m stop\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43;01mAnthropic\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mLLM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_AnthropicCommon\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Anthropic large language models.\u001b[39;49;00m\n\u001b[0;32m    147\u001b[0m \n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;43;03m    To use, you should have the ``anthropic`` python package installed, and the\u001b[39;49;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;43;03m            response = model(prompt)\u001b[39;49;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43;01mConfig\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_model_construction.py:224\u001b[0m, in \u001b[0;36mModelMetaclass.__new__\u001b[1;34m(mcs, cls_name, bases, namespace, __pydantic_generic_metadata__, __pydantic_reset_parent_namespace__, _create_model_module, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_wrapper\u001b[38;5;241m.\u001b[39mfrozen \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__hash__\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m namespace:\n\u001b[0;32m    222\u001b[0m     set_default_hash_func(\u001b[38;5;28mcls\u001b[39m, bases)\n\u001b[1;32m--> 224\u001b[0m \u001b[43mcomplete_model_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcls_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraise_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mns_resolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mns_resolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_model_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_create_model_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# If this is placed before the complete_model_class call above,\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# the generic computed fields return type is set to PydanticUndefined\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_computed_fields__ \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    236\u001b[0m     k: v\u001b[38;5;241m.\u001b[39minfo \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_decorators__\u001b[38;5;241m.\u001b[39mcomputed_fields\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    237\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_model_construction.py:602\u001b[0m, in \u001b[0;36mcomplete_model_class\u001b[1;34m(cls, cls_name, config_wrapper, raise_errors, ns_resolver, create_model_module)\u001b[0m\n\u001b[0;32m    595\u001b[0m handler \u001b[38;5;241m=\u001b[39m CallbackGetCoreSchemaHandler(\n\u001b[0;32m    596\u001b[0m     partial(gen_schema\u001b[38;5;241m.\u001b[39mgenerate_schema, from_dunder_get_core_schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m    597\u001b[0m     gen_schema,\n\u001b[0;32m    598\u001b[0m     ref_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munpack\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    599\u001b[0m )\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 602\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_pydantic_core_schema__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PydanticUndefinedAnnotation \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_errors:\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\main.py:702\u001b[0m, in \u001b[0;36mBaseModel.__get_pydantic_core_schema__\u001b[1;34m(cls, source, handler)\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_generic_metadata__[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morigin\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    700\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_core_schema__\n\u001b[1;32m--> 702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_schema_generation_shared.py:84\u001b[0m, in \u001b[0;36mCallbackGetCoreSchemaHandler.__call__\u001b[1;34m(self, source_type)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source_type: Any, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mCoreSchema:\n\u001b[1;32m---> 84\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     ref \u001b[38;5;241m=\u001b[39m schema\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ref_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto-def\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:610\u001b[0m, in \u001b[0;36mGenerateSchema.generate_schema\u001b[1;34m(self, obj, from_dunder_get_core_schema)\u001b[0m\n\u001b[0;32m    607\u001b[0m         schema \u001b[38;5;241m=\u001b[39m from_property\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 610\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_schema_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    612\u001b[0m metadata_js_function \u001b[38;5;241m=\u001b[39m _extract_get_pydantic_json_schema(obj, schema)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadata_js_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:879\u001b[0m, in \u001b[0;36mGenerateSchema._generate_schema_inner\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lenient_issubclass(obj, BaseModel):\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type_stack\u001b[38;5;241m.\u001b[39mpush(obj):\n\u001b[1;32m--> 879\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, PydanticRecursiveRef):\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema\u001b[38;5;241m.\u001b[39mdefinition_reference_schema(schema_ref\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mtype_ref)\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:691\u001b[0m, in \u001b[0;36mGenerateSchema._model_schema\u001b[1;34m(self, cls)\u001b[0m\n\u001b[0;32m    679\u001b[0m     model_schema \u001b[38;5;241m=\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mmodel_schema(\n\u001b[0;32m    680\u001b[0m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m    681\u001b[0m         inner_schema,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    687\u001b[0m         ref\u001b[38;5;241m=\u001b[39mmodel_ref,\n\u001b[0;32m    688\u001b[0m     )\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    690\u001b[0m     fields_schema: core_schema\u001b[38;5;241m.\u001b[39mCoreSchema \u001b[38;5;241m=\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mmodel_fields_schema(\n\u001b[1;32m--> 691\u001b[0m         \u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_md_field_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m,\n\u001b[0;32m    692\u001b[0m         computed_fields\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    693\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_computed_field_schema(d, decorators\u001b[38;5;241m.\u001b[39mfield_serializers)\n\u001b[0;32m    694\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m computed_fields\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[0;32m    695\u001b[0m         ],\n\u001b[0;32m    696\u001b[0m         extras_schema\u001b[38;5;241m=\u001b[39mextras_schema,\n\u001b[0;32m    697\u001b[0m         model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[0;32m    698\u001b[0m     )\n\u001b[0;32m    699\u001b[0m     inner_schema \u001b[38;5;241m=\u001b[39m apply_validators(fields_schema, decorators\u001b[38;5;241m.\u001b[39mroot_validators\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    700\u001b[0m     new_inner_schema \u001b[38;5;241m=\u001b[39m define_expected_missing_refs(inner_schema, recursively_defined_type_refs())\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:691\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    679\u001b[0m     model_schema \u001b[38;5;241m=\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mmodel_schema(\n\u001b[0;32m    680\u001b[0m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m    681\u001b[0m         inner_schema,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    687\u001b[0m         ref\u001b[38;5;241m=\u001b[39mmodel_ref,\n\u001b[0;32m    688\u001b[0m     )\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    690\u001b[0m     fields_schema: core_schema\u001b[38;5;241m.\u001b[39mCoreSchema \u001b[38;5;241m=\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mmodel_fields_schema(\n\u001b[1;32m--> 691\u001b[0m         {k: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_md_field_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorators\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m fields\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[0;32m    692\u001b[0m         computed_fields\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    693\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_computed_field_schema(d, decorators\u001b[38;5;241m.\u001b[39mfield_serializers)\n\u001b[0;32m    694\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m computed_fields\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[0;32m    695\u001b[0m         ],\n\u001b[0;32m    696\u001b[0m         extras_schema\u001b[38;5;241m=\u001b[39mextras_schema,\n\u001b[0;32m    697\u001b[0m         model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[0;32m    698\u001b[0m     )\n\u001b[0;32m    699\u001b[0m     inner_schema \u001b[38;5;241m=\u001b[39m apply_validators(fields_schema, decorators\u001b[38;5;241m.\u001b[39mroot_validators\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    700\u001b[0m     new_inner_schema \u001b[38;5;241m=\u001b[39m define_expected_missing_refs(inner_schema, recursively_defined_type_refs())\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:1071\u001b[0m, in \u001b[0;36mGenerateSchema._generate_md_field_schema\u001b[1;34m(self, name, field_info, decorators)\u001b[0m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate_md_field_schema\u001b[39m(\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1066\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   1067\u001b[0m     field_info: FieldInfo,\n\u001b[0;32m   1068\u001b[0m     decorators: DecoratorInfos,\n\u001b[0;32m   1069\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mModelField:\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prepare a ModelField to represent a model field.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1071\u001b[0m     common_field \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_common_field_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorators\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema\u001b[38;5;241m.\u001b[39mmodel_field(\n\u001b[0;32m   1073\u001b[0m         common_field[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   1074\u001b[0m         serialization_exclude\u001b[38;5;241m=\u001b[39mcommon_field[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserialization_exclude\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1078\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mcommon_field[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   1079\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:1263\u001b[0m, in \u001b[0;36mGenerateSchema._common_field_schema\u001b[1;34m(self, name, field_info, decorators)\u001b[0m\n\u001b[0;32m   1259\u001b[0m         schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_annotations(\n\u001b[0;32m   1260\u001b[0m             source_type, annotations \u001b[38;5;241m+\u001b[39m validators_from_decorators, transform_inner_schema\u001b[38;5;241m=\u001b[39mset_discriminator\n\u001b[0;32m   1261\u001b[0m         )\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1263\u001b[0m         schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_annotations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m            \u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m            \u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidators_from_decorators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;66;03m# This V1 compatibility shim should eventually be removed\u001b[39;00m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;66;03m# push down any `each_item=True` validators\u001b[39;00m\n\u001b[0;32m   1270\u001b[0m \u001b[38;5;66;03m# note that this won't work for any Annotated types that get wrapped by a function validator\u001b[39;00m\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;66;03m# but that's okay because that didn't exist in V1\u001b[39;00m\n\u001b[0;32m   1272\u001b[0m this_field_validators \u001b[38;5;241m=\u001b[39m filter_field_decorator_info_by_field(decorators\u001b[38;5;241m.\u001b[39mvalidators\u001b[38;5;241m.\u001b[39mvalues(), name)\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2056\u001b[0m, in \u001b[0;36mGenerateSchema._apply_annotations\u001b[1;34m(self, source_type, annotations, transform_inner_schema)\u001b[0m\n\u001b[0;32m   2051\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   2052\u001b[0m     get_inner_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_wrapped_inner_schema(\n\u001b[0;32m   2053\u001b[0m         get_inner_schema, annotation, pydantic_js_annotation_functions\n\u001b[0;32m   2054\u001b[0m     )\n\u001b[1;32m-> 2056\u001b[0m schema \u001b[38;5;241m=\u001b[39m \u001b[43mget_inner_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pydantic_js_annotation_functions:\n\u001b[0;32m   2058\u001b[0m     core_metadata \u001b[38;5;241m=\u001b[39m schema\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_schema_generation_shared.py:84\u001b[0m, in \u001b[0;36mCallbackGetCoreSchemaHandler.__call__\u001b[1;34m(self, source_type)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source_type: Any, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mCoreSchema:\n\u001b[1;32m---> 84\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     ref \u001b[38;5;241m=\u001b[39m schema\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ref_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto-def\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2037\u001b[0m, in \u001b[0;36mGenerateSchema._apply_annotations.<locals>.inner_handler\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m   2035\u001b[0m from_property \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_schema_from_property(obj, source_type)\n\u001b[0;32m   2036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_property \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2037\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_schema_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2038\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2039\u001b[0m     schema \u001b[38;5;241m=\u001b[39m from_property\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:884\u001b[0m, in \u001b[0;36mGenerateSchema._generate_schema_inner\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, PydanticRecursiveRef):\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema\u001b[38;5;241m.\u001b[39mdefinition_reference_schema(schema_ref\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mtype_ref)\n\u001b[1;32m--> 884\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:986\u001b[0m, in \u001b[0;36mGenerateSchema.match_type\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    984\u001b[0m origin \u001b[38;5;241m=\u001b[39m get_origin(obj)\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_match_generic_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_prepare_pydantic_annotations_for_known_type(obj, ())\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:1014\u001b[0m, in \u001b[0;36mGenerateSchema._match_generic_type\u001b[1;34m(self, obj, origin)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_type_alias_type_schema(obj)\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _typing_extra\u001b[38;5;241m.\u001b[39morigin_is_union(origin):\n\u001b[1;32m-> 1014\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_union_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m origin \u001b[38;5;129;01min\u001b[39;00m TUPLE_TYPES:\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tuple_schema(obj)\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:1325\u001b[0m, in \u001b[0;36mGenerateSchema._union_schema\u001b[1;34m(self, union_type)\u001b[0m\n\u001b[0;32m   1323\u001b[0m         nullable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1325\u001b[0m         choices\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(choices) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1328\u001b[0m     s \u001b[38;5;241m=\u001b[39m choices[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:612\u001b[0m, in \u001b[0;36mGenerateSchema.generate_schema\u001b[1;34m(self, obj, from_dunder_get_core_schema)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    610\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_schema_inner(obj)\n\u001b[1;32m--> 612\u001b[0m metadata_js_function \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_get_pydantic_json_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadata_js_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    614\u001b[0m     metadata_schema \u001b[38;5;241m=\u001b[39m resolve_original_schema(schema, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefs\u001b[38;5;241m.\u001b[39mdefinitions)\n",
      "File \u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2395\u001b[0m, in \u001b[0;36m_extract_get_pydantic_json_schema\u001b[1;34m(tp, schema)\u001b[0m\n\u001b[0;32m   2393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_custom_v2_modify_js_func:\n\u001b[0;32m   2394\u001b[0m         cls_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(tp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 2395\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[0;32m   2396\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `__modify_schema__` method is not supported in Pydantic v2. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2397\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse `__get_pydantic_json_schema__` instead\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in class `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mcls_name\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   2398\u001b[0m             code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom-json-schema\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   2399\u001b[0m         )\n\u001b[0;32m   2401\u001b[0m \u001b[38;5;66;03m# handle GenericAlias' but ignore Annotated which \"lies\" about its origin (in this case it would be `int`)\u001b[39;00m\n\u001b[0;32m   2402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__origin__\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _typing_extra\u001b[38;5;241m.\u001b[39mis_annotated(tp):\n",
      "\u001b[1;31mPydanticUserError\u001b[0m: The `__modify_schema__` method is not supported in Pydantic v2. Use `__get_pydantic_json_schema__` instead in class `SecretStr`.\n\nFor further information visit https://errors.pydantic.dev/2.10/u/custom-json-schema"
     ]
    }
   ],
   "source": [
    "# 필요한 모듈 임포트\n",
    "import whisper\n",
    "import os\n",
    "import pyttsx3\n",
    "import threading\n",
    "import base64\n",
    "import streamlit as st\n",
    "#from langchain_openai import ChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from RealtimeSTT import AudioToTextRecorder\n",
    "import pyautogui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whisper 모델 로드\n",
    "model = whisper.load_model(\"base\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error in __cdecl faiss::FileIOReader::FileIOReader(const char *) at D:\\a\\faiss-wheels\\faiss-wheels\\faiss\\faiss\\impl\\io.cpp:68: Error: 'f' failed: could not open refer.txt\\index.faiss for reading: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14500\\540378294.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mseparator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# separator로 올바르게 설정\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mchunk_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mchunk_overlap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mretriever\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"refer.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(cls, folder_path, embeddings, index_name, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         \"\"\"\n\u001b[0;32m   1101\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m         \u001b[1;31m# load index separately since it is not picklable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m         \u001b[0mfaiss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdependable_faiss_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m         index = faiss.read_index(\n\u001b[0m\u001b[0;32m   1105\u001b[0m             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m\"{index_name}.faiss\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m         )\n\u001b[0;32m   1107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\INO04\\anaconda3\\envs\\qwer\\Lib\\site-packages\\faiss\\swigfaiss_avx2.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m  10811\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10812\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_swigfaiss_avx2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Error in __cdecl faiss::FileIOReader::FileIOReader(const char *) at D:\\a\\faiss-wheels\\faiss-wheels\\faiss\\faiss\\impl\\io.cpp:68: Error: 'f' failed: could not open refer.txt\\index.faiss for reading: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Langchain 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.7)\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",  # separator로 올바르게 설정\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "retriever = FAISS.load_local(\"./refer.txt\", OpenAIEmbeddings())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 사용자 질문을 처리하는 함수\n",
    "def ask_gpt(user_question):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are an intelligent assistant.\"),\n",
    "            (\"human\", \"{question}\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = (\n",
    "        {\n",
    "            \"context\": retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "    )\n",
    "\n",
    "    result = chain.invoke(user_question)\n",
    "    return result.content\n",
    "\n",
    "\n",
    "# 음성을 합성하는 함수 (TTS)\n",
    "def speak(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "\n",
    "# 이미지 Base64 변환 함수\n",
    "def get_image_base64(image_path):\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        return base64.b64encode(img_file.read()).decode()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Streamlit 세션 상태 초기화\n",
    "if 'chat_history' not in st.session_state:\n",
    "    st.session_state.chat_history = []\n",
    "if 'question' not in st.session_state:\n",
    "    st.session_state.question = \"\"\n",
    "if 'mode' not in st.session_state:\n",
    "    st.session_state.mode = \"voice\"  # 기본 모드 = 음성\n",
    "\n",
    "\n",
    "# 이미지 경로 설정\n",
    "ai_avatar = \"karina_1-removebg-preview.png\"  # AI 아바타 이미지\n",
    "user_avatar = \"사람이미지_1.jpg\"  # 사용자 아바타 이미지\n",
    "\n",
    "\n",
    "# CSS 스타일 정의 (if __name__ == \"__main__\" 밖에 위치)\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    ".chat-container {\n",
    "    display: flex;\n",
    "    align-items: start;\n",
    "    margin-bottom: 20px;\n",
    "    width: 100%;\n",
    "}\n",
    "\n",
    ".chat-image {\n",
    "    width: 100px;\n",
    "    height: 150px;\n",
    "    border-radius: 10%;\n",
    "    margin: 0 15px;\n",
    "    object-fit : cover;\n",
    "}\n",
    ".chat-image.ai {\n",
    "    flex-direction: row-reverse;\n",
    "    align: right;\n",
    "    align-items: flex-start;\n",
    "    justify-content: flex-end;\n",
    "}\n",
    ".chat-message {\n",
    "    background-color: #f0f2f6;\n",
    "    padding: 10px;\n",
    "    border-radius: 10px;\n",
    "    max-width: 80%;\n",
    "}\n",
    "\n",
    ".chat-container.ai {\n",
    "    flex-direction: row-reverse;\n",
    "    text-align: auto;\n",
    "}         \n",
    "            \n",
    ".chat-message.ai {\n",
    "    margin-right: 0;\n",
    "    text-align: auto;\n",
    "}   \n",
    "\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# 질문 입력 부분\n",
    "question = st.text_input(\"언제든 편하게 물어보세요\", value=st.session_state.question, key=\"user_input\")\n",
    "\n",
    "# 질문에 대한 답변을 생성하는 버튼\n",
    "if question and (st.button('답변') or question != st.session_state.get('previous_question', '')):\n",
    "    st.session_state['previous_question'] = question\n",
    "    answer = ask_gpt(question)  # GPT-3 모델을 호출하여 답변을 받습니다.\n",
    "\n",
    "    st.session_state.chat_history.append(f\"Question: {question}\")\n",
    "    st.session_state.chat_history.append(f\"Answer: {answer}\")\n",
    "    st.session_state.question = \"\"  # 입력 필드 클리어\n",
    "\n",
    "    # 대화 내역 표시\n",
    "    for message in st.session_state.chat_history:\n",
    "        if message.startswith(\"Question:\"):\n",
    "            # 사용자 메시지\n",
    "            st.markdown(\n",
    "                f\"\"\"\n",
    "                <div class=\"chat-container\">\n",
    "                    <img src=\"data:image/jpeg;base64,{get_image_base64(user_avatar)}\" class=\"chat-image\">\n",
    "                    <div class=\"chat-message\">{message}</div>\n",
    "                </div>\n",
    "                \"\"\",\n",
    "                unsafe_allow_html=True\n",
    "            )\n",
    "        else: \n",
    "            # ai 답변\n",
    "            st.markdown(\n",
    "                f\"\"\"\n",
    "                <div class=\"chat-container ai\">\n",
    "                    <img src=\"data:image/jpeg;base64,{get_image_base64(ai_avatar)}\" class=\"chat-image\">\n",
    "                    <div class=\"chat-message ai\">{message}</div>\n",
    "                </div>\n",
    "                \"\"\", \n",
    "                unsafe_allow_html=True\n",
    "            )\n",
    "\n",
    "    # 자동 스크롤 아래로\n",
    "    st.markdown(\"<script>window.scrollTo(0, document.body.scrollHeight);</script>\", unsafe_allow_html=True)\n",
    "\n",
    "else:\n",
    "    st.error(\"Please enter a question.\")\n",
    "\n",
    "# Streamlit 페이지 설정\n",
    "st.set_page_config(layout=\"wide\", page_title=\"AI Assistant\")\n",
    "st.title(\"AI Assistant\")\n",
    "\n",
    "# 음성 인식 및 처리 (STT)\n",
    "def listen_for_audio():\n",
    "    recorder = AudioToTextRecorder()\n",
    "    while True:\n",
    "        recorder.text(process_command)\n",
    "\n",
    "# STT 명령을 처리하는 함수\n",
    "def process_command(text):\n",
    "    print(f\"사용자 요구사항: {text}\")\n",
    "    response = respond_to_command(text)\n",
    "    print(response)\n",
    "    pyautogui.typewrite(response)\n",
    "\n",
    "# 명령어에 대한 응답을 처리하는 함수\n",
    "def respond_to_command(command):\n",
    "    if \"날씨\" in command:\n",
    "        return \"오늘의 날씨는 맑습니다.\"\n",
    "    elif \"시간\" in command:\n",
    "        return \"현재 시간은 3시입니다.\"\n",
    "    else:\n",
    "        return \"요청을 이해하지 못했습니다.\"\n",
    "\n",
    "# 자바스크립트 코드 (복사 및 평가 기능)\n",
    "st.markdown(\"\"\"\n",
    "<div id=\"scroll-top\" onclick=\"window.scrollTo(0,0)\">⬆️</div>\n",
    "<div id=\"scroll-bottom\" onclick=\"window.scrollTo(0,document.body.scrollHeight)\">⬇️</div>\n",
    "<script>\n",
    "    function copyToClipboard(text) {\n",
    "        navigator.clipboard.writeText(text).then(() => {\n",
    "            alert('Copied to clipboard');\n",
    "        });\n",
    "    }\n",
    "\n",
    "    function evaluateResponse(evaluation) {\n",
    "        alert('You rated this response as: ' + evaluation);\n",
    "    }\n",
    "</script>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# `__main__`에서 음성 인식을 위한 스레드를 시작하는 부분\n",
    "if __name__ == \"__main__\":\n",
    "    audio_thread = threading.Thread(target=listen_for_audio)\n",
    "    audio_thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
